def parse_art_summary_and_dpmv(poscar_path: Path, out_dir: Path) -> tuple[list[ARTSummaryEntry], list[DPmVEntry], list[DPmVEntry]]:

    structure = Structure.from_file(poscar_path)
    dir_path = poscar_path.parent

    def copy_trim(source_pattern: str, dest_name: str):
        src = sorted(out_dir.glob(source_pattern))[0]
        dest = out_dir / dest_name
        with src.open() as f_in, dest.open("w") as f_out:
            f_out.writelines(f_in.readlines()[1:])  # skip header
        return dest

    # Create arp-*.dat files 
    arp_val_path = copy_trim("arp_shg_val_*.txt", "arp-val.dat")
    arp_con_path = copy_trim("arp_shg_con_*.txt", "arp-con.dat")
    arp_nshg_path = copy_trim("arp_nshg_*.txt", "arp-nshg.dat")
    arp_dshg_path = copy_trim("arp_dshg_*.txt", "arp-dshg.dat")

    # Generate d-PmV.dat from arp-nshg.dat
    d_pmv = []
    with arp_nshg_path.open() as f:
        for line in f:
            parts = line.split()
            nbands = int(float(parts[0]))
            val = float(parts[2]) * (4 / 3 * np.pi * 10 / 2)
            d_pmv.append(DPmVEntry(nbands=nbands, value=val, label="prf-PmV"))

    with open(out_dir / "d-PmV.dat", "w") as f:
        for entry in d_pmv:
            f.write(f"{entry.nbands} {entry.value:.4f}\n")

    # Generate dshg-PmV.dat from arp-dshg.dat
    dshg_pmv = []
    with arp_dshg_path.open() as f:
        for line in f:
            parts = line.split()
            nbands = int(float(parts[0]))
            val = float(parts[2]) * (4 / 3 * np.pi * 10 / 2)
            dshg_pmv.append(DPmVEntry(nbands=nbands, value=val, label="dprf-PmV"))

    with open(out_dir / "dshg-PmV.dat", "w") as f:
        for entry in dshg_pmv:
            f.write(f"{entry.nbands} {entry.value:.6f}\n")

    # Parse summary from original TXT files
    val_lines = arp_val_path.read_text().splitlines()
    con_lines = arp_con_path.read_text().splitlines()
    all_lines = (out_dir / "arp_nonlin.txt").read_text().splitlines()[9:]

    clean_lines = [
        ln for ln in all_lines
        if ln.strip()                             
        and not ln.lstrip().startswith("#")      
        and not ln.lstrip().startswith("tot")  
    ]


    total_sum = sum(float(line.split()[2]) for line in clean_lines)
    
    # Check if total_sum is zero to avoid division by zero
    if total_sum == 0:
        raise ValueError(
            "total_sum is zero, which would cause division by zero. "
            "This likely means there are no valid lines in arp_nonlin.txt or all values are zero."
        )

    atom_types = structure.composition.element_composition.as_dict()
    atom_type_list = list(atom_types.keys())
    atom_counts = list(atom_types.values())

    # Filter val_lines and con_lines the same way as clean_lines to ensure consistent indexing
    clean_val_lines = [
        ln for ln in val_lines
        if ln.strip()
        and not ln.lstrip().startswith("#")
        and not ln.lstrip().startswith("tot")
    ]
    
    clean_con_lines = [
        ln for ln in con_lines
        if ln.strip()
        and not ln.lstrip().startswith("#")
        and not ln.lstrip().startswith("tot")
    ]
    
    # Verify all three have the same length
    if not (len(clean_lines) == len(clean_val_lines) == len(clean_con_lines)):
        raise ValueError(
            f"Mismatch in filtered line counts: "
            f"clean_lines={len(clean_lines)}, "
            f"clean_val_lines={len(clean_val_lines)}, "
            f"clean_con_lines={len(clean_con_lines)}"
        )
    
    summary_entries = []
    # Initialize SEPARATE indices for each file stream
    total_idx = 0
    valence_idx = 0
    conduction_idx = 0
    
    for atype, count in zip(atom_type_list, atom_counts):
        occ_s = occ_p = occ_d = vb_s = vb_p = vb_d = cb_s = cb_p = cb_d = 0
        for _ in range(int(count)):
            # Read from TOTAL (arp_nonlin.txt) - uses total_idx
            s = float(clean_lines[total_idx + 0].split()[2])
            p = float(clean_lines[total_idx + 1].split()[2])
            d = float(clean_lines[total_idx + 2].split()[2])
            total_idx += 3

            # Read from VALENCE (arp-val.dat) - uses valence_idx (INDEPENDENT!)
            sv = float(clean_val_lines[valence_idx + 0].split()[2])
            pv = float(clean_val_lines[valence_idx + 1].split()[2])
            dv = float(clean_val_lines[valence_idx + 2].split()[2])
            valence_idx += 3

            # Read from CONDUCTION (arp-con.dat) - uses conduction_idx (INDEPENDENT!)
            sc = float(clean_con_lines[conduction_idx + 0].split()[2])
            pc = float(clean_con_lines[conduction_idx + 1].split()[2])
            dc = float(clean_con_lines[conduction_idx + 2].split()[2])
            conduction_idx += 3

            occ_s += 100 * s / total_sum
            occ_p += 100 * p / total_sum
            occ_d += 100 * d / total_sum
            vb_s += 100 * sv / total_sum
            vb_p += 100 * pv / total_sum
            vb_d += 100 * dv / total_sum
            cb_s += 100 * sc / total_sum
            cb_p += 100 * pc / total_sum
            cb_d += 100 * dc / total_sum

        tot = occ_s + occ_p + occ_d
        vb = vb_s + vb_p + vb_d
        cb = cb_s + cb_p + cb_d
        ind = tot / int(count)

        entry = ARTSummaryEntry(
            atom_type=str(atype),
            num_atoms=int(count),
            ind=ind,
            total=tot,
            vb=vb,
            cb=cb,
            vb_s=vb_s, vb_p=vb_p, vb_d=vb_d,
            cb_s=cb_s, cb_p=cb_p, cb_d=cb_d,
            tot_s=occ_s, tot_p=occ_p, tot_d=occ_d
        )
        summary_entries.append(entry)

    # Write result.art_TOT
    with open(dir_path / "result.art_TOT", "w") as f:
        f.write("Type Natom IND TOT VB CB VB_s VB_p VB_d CB_s CB_p CB_d TOT_s TOT_p TOT_d\n")
        for e in summary_entries:
            f.write(
                f"{e.atom_type} {e.num_atoms} "
                f"{e.ind:.4f} {e.total:.4f} {e.vb:.4f} {e.cb:.4f} "
                f"{e.vb_s:.4f} {e.vb_p:.4f} {e.vb_d:.4f} "
                f"{e.cb_s:.4f} {e.cb_p:.4f} {e.cb_d:.4f} "
                f"{e.tot_s:.4f} {e.tot_p:.4f} {e.tot_d:.4f}\n"
            )

    # Clean up temp files (keep only arp-dshg.dat like shell script)
    for temp in [arp_val_path, arp_con_path, arp_nshg_path]:
        try:
            temp.unlink()
        except Exception as e:
            print(f"Warning: couldn't remove {temp}: {e}")

    # --- Generate d_energy.dat and dshg_energy.dat (energy-band.dat must exist) ---
    energy_band = dir_path / "energy-band.dat"
    dpmv_file = out_dir / "d-PmV.dat"
    dshgpmv_file = out_dir / "dshg-PmV.dat"

    if energy_band.exists() and dpmv_file.exists() and dshgpmv_file.exists():
        def paste_and_extract(energy_file, data_file, output_file):
            with open(energy_file) as f1, open(data_file) as f2, open(output_file, "w") as fout:
                for l1, l2 in zip(f1, f2):
                    p1 = l1.split()
                    p2 = l2.split()
                    if len(p1) >= 2 and len(p2) >= 2:
                        # column 2 from energy-band.dat and column 2 from data file
                        fout.write(f"{p1[1]} {p2[1]}\n")

        # Generate d_energy.dat and dshg_energy.dat in main dir
        if energy_band.exists() and dpmv_file.exists() and dshgpmv_file.exists():
            d_energy_out = dir_path / "d_energy.dat"
            dshg_energy_out = dir_path / "dshg_energy.dat"

            paste_and_extract(energy_band, dpmv_file, d_energy_out)
            paste_and_extract(energy_band, dshgpmv_file, dshg_energy_out)
        else:
            print("Warning: One or more input files for d_energy.dat generation are missing.")
            
        d_energy = []
        dshg_energy = []


        if d_energy_out.exists():
            with d_energy_out.open() as f:
                for line in f:
                    parts = line.split()
                    if len(parts) >= 2:
                        d_energy.append((float(parts[0]), float(parts[1])))

        if dshg_energy_out.exists():
            with dshg_energy_out.open() as f:
                for line in f:
                    parts = line.split()
                    if len(parts) >= 2:
                       dshg_energy.append((float(parts[0]), float(parts[1])))

    return summary_entries, d_pmv, dshg_pmv, d_energy, dshg_energy
